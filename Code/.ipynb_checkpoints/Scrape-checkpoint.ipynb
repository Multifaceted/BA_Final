{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_restaurant(restaurant_name, location_name):\n",
    "   \n",
    "    \"\"\"\n",
    "    Search restaurant by its name and location, get the fuzzy match and return its attributes and reviews.\n",
    "    An index quantifying similarity and an error_code indicating potential errors are also returned.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    TEMPLATE\n",
    "    (restaurant_name = str, location_name = str) -> attributes = pd.Series, reviewer = pd.DataFrame, fetched_restaurant = str, similarity_index = int, error_code = int / str\n",
    "    \n",
    "    INPUT\n",
    "    restaurant_name: separated by space if multiple words incur\n",
    "    location_name: in the order of: Building, Street, Boroughs. separated by space\n",
    "    \n",
    "    OUTPUT\n",
    "    attributes: attributes of the restaurant, dummies with few exceptions\n",
    "    review: include rating, text, date and reviewees' info\n",
    "    fetched_restaurant: name of the fetched restaurant, possibly different from search name\n",
    "    similarity_index: similarity between fetched name and search name, measured by fuzz.ratio function\n",
    "    error_code: if empty str, nomral / if int, no data is returned / if non-empty str, incomplete data is returned\n",
    "    ''  normal\n",
    "    -1  fail to connect to search page\n",
    "    -2  time out, fail to fetch potential restaurants list\n",
    "    -3  fail to connect to restaurant page\n",
    "    str errouneous reveiws indicated by str. '0/0/20/' indicates 2 errouneous reviews in the first batch of 20 reviews and 1 in the second.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    from proxycrawl.proxycrawl_api import ProxyCrawlAPI\n",
    "    from bs4 import BeautifulSoup\n",
    "    from fuzzywuzzy import fuzz\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import time\n",
    "    \n",
    "    \n",
    "    # set error_code to be normal\n",
    "    error_code = 0\n",
    "    \n",
    "    \n",
    "    # set maximal trails to be 100\n",
    "    n = 0\n",
    "    \n",
    "    MAXIMUM_TRAIL = 3\n",
    "    while(n < MAXIMUM_TRAIL):\n",
    "        time.sleep(np.random.uniform(5, 10))\n",
    "        search_link = 'https://www.yelp.com/search?find_desc=' + restaurant_name + '&find_loc=' + location_name + '&ns=1'\n",
    "        try:\n",
    "            search_content = BeautifulSoup(requests.get(search_link).text)\n",
    "        except:\n",
    "            error_code = -1\n",
    "            return (None, None, None, None, error_code)\n",
    "        fetched_restaurants = search_content.find_all('a', {'class': \"lemon--a__373c0__1_OnJ link__373c0__29943 link-color--blue-dark__373c0__1mhJo link-size--inherit__373c0__2JXk5\"})\n",
    "        if fetched_restaurants == []:\n",
    "            fetched_restaurants = search_content.find_all('a', {'class': \"biz-name js-analytics-click\"})\n",
    "        if fetched_restaurants != []:\n",
    "            break\n",
    "        n += 1\n",
    "    \n",
    "    if n == MAXIMUM_TRAIL:\n",
    "        error_code = -2\n",
    "        return (None, None, None, None, error_code)\n",
    "    \n",
    "    del n \n",
    "    \n",
    "    \n",
    "    # choose the most matching restaurant on the first seach page\n",
    "    similarity = np.zeros(len(fetched_restaurants), dtype = 'int')\n",
    "    for fetched_restaurant_index, fetched_restaurant in enumerate(fetched_restaurants):\n",
    "        similarity[fetched_restaurant_index] = fuzz.ratio(restaurant_name.strip().lower(), fetched_restaurant.get_text().strip().lower())\n",
    "    \n",
    "    fetched_restaurant = fetched_restaurants[similarity.argmax()].get_text().strip()\n",
    "    similarity_index = similarity.max()\n",
    "    \n",
    "    \n",
    "    # set number of reviews to be 0\n",
    "    n_reviews = 0\n",
    "    \n",
    "    # fetch restaurant data\n",
    "    try:\n",
    "        restaurant_link = 'https://www.yelp.com' + fetched_restaurants[similarity.argmax()].attrs['href'].split('?')[0] + '?start=' + str(n_reviews)\n",
    "        restaurant_content = BeautifulSoup(requests.get(restaurant_link).text)\n",
    "    except:\n",
    "        error_code = -3\n",
    "        return (None, None, None, None, error_code)\n",
    "    \n",
    "    try:\n",
    "        overall_rating = restaurant_content.find('div', {'class': 'biz-rating biz-rating-very-large clearfix'}).find_next().attrs['title'].strip().split()[0].strip()\n",
    "    except:\n",
    "        overall_rating = np.nan\n",
    "    try:\n",
    "        overall_reviews = restaurant_content.find('span', {'class': 'review-count rating-qualifier'}).get_text().strip().split(' ')[0].strip()\n",
    "    except:\n",
    "        overall_reviews = np.nan\n",
    "    try:\n",
    "        price_range = restaurant_content.find('dd', {'class': 'nowrap price-description'}).get_text().strip()\n",
    "    except:\n",
    "        price_range = np.nan\n",
    "    try:\n",
    "        health_score = restaurant_content.find('dd', {'class': 'nowrap health-score-description'}).get_text().strip()\n",
    "    except:\n",
    "        health_score = np.nan\n",
    "    head = restaurant_content.find('div', {'class':'short-def-list'})\n",
    "    try:\n",
    "        names = head.find_all('dt')\n",
    "        values = head.find_all('dd')\n",
    "    except:\n",
    "        pass\n",
    "    attributes = pd.Series(np.full(30, np.nan), index = ['Accepts Credit Cards',\n",
    "                                                         'Accepts Bitcoin',\n",
    "                                                         'Accepts Insurance',\n",
    "                                                         'Alcohol',\n",
    "                                                         'Appointment Only',\n",
    "                                                         'Caters',\n",
    "                                                         'Coat Check',\n",
    "                                                         'Delivers',\n",
    "                                                         'Dogs Allowed'\n",
    "                                                         'Hair Types Specialized In',\n",
    "                                                         'Happy Hour',\n",
    "                                                         'TV',\n",
    "                                                         'Outdoor Seating',\n",
    "                                                         'Parking',\n",
    "                                                         'Smoking Allowed',\n",
    "                                                         'Take-out',\n",
    "                                                         'Takes Reservations',\n",
    "                                                         'Waiter Service',\n",
    "                                                         'Wheelchair Accessible',\n",
    "                                                         'Wi-Fi',\n",
    "                                                         'Opened 24hrs',\n",
    "                                                         'Gender Neutral Bathrooms'\n",
    "                                                         'Ambience',\n",
    "                                                         'Attire',\n",
    "                                                         'Best Nights',\n",
    "                                                         'Good For Dancing',\n",
    "                                                         'Good For Groups',\n",
    "                                                         'Good For Kids',\n",
    "                                                         'Good For Meals Served',\n",
    "                                                         'Music',\n",
    "                                                         'Noise Level',\n",
    "                                                         'Price Range'\n",
    "                                                        ])\n",
    "    for name, value in zip(names, values):\n",
    "        if name.get_text().strip().capitalize() in attributes:\n",
    "            attributes[name.get_text().strip().capitalize()] = value.get_text().strip()\n",
    "    \n",
    "    \n",
    "    attributes = attributes.append(pd.Series({'price_range': price_range, \n",
    "                                              'health_score': health_score, \n",
    "                                              'overall_rating': overall_rating, \n",
    "                                              'overall_reviews': overall_reviews}))\n",
    "    \n",
    "    # fetch reviews data\n",
    "    reviewer = pd.DataFrame({'er_name': [],\n",
    "                             'er_location': [],\n",
    "                             'er_freinds': [],\n",
    "                             'er_reviews':[],\n",
    "                             'er_photos': [],\n",
    "                             'er_rating': [],\n",
    "                             'er_date': [],\n",
    "                             'er_text': [],\n",
    "                             'er_useful': [],\n",
    "                             'er_funny': [],\n",
    "                             'er_cool': []\n",
    "                            })\n",
    "    \n",
    "    error_code = \"\"\n",
    "    \n",
    "    MAXIMUM_REVIEW = 20000\n",
    "    while(n_reviews < MAXIMUM_REVIEW):\n",
    "        try:\n",
    "            reviews = restaurant_content.find_all('div', {'class':'review review--with-sidebar'})\n",
    "            if reviews == []:\n",
    "                break\n",
    "            for review in reviews:\n",
    "                text_tag = review.find('p')\n",
    "                if text_tag.attrs['lang'].strip() != 'en':\n",
    "                    continue\n",
    "                er_text = text_tag.get_text().strip()\n",
    "                er_name = review.find('a', {'class': 'user-display-name js-analytics-click'}).get_text().strip()\n",
    "                er_location = review.find('li', {'class': 'user-location responsive-hidden-small'}).get_text().strip()\n",
    "                try:\n",
    "                    er_friends = review.find('li', {'class': 'friend-count responsive-small-display-inline-block'}).get_text().strip().split(' ')[0].strip()\n",
    "                except:\n",
    "                    er_friends = 0\n",
    "                try:\n",
    "                    er_reviews = review.find('li', {'class': 'review-count responsive-small-display-inline-block'}).get_text().strip().split(' ')[0].strip()\n",
    "                except:\n",
    "                    er_reviews = 0\n",
    "                try:\n",
    "                    er_photos = review.find('li', {'class': 'photo-count responsive-small-display-inline-block'}).get_text().strip().split(' ')[0].strip()\n",
    "                except:\n",
    "                    er_photos = 0\n",
    "                er_rating = review.find('div', {'class': 'biz-rating biz-rating-large clearfix'}).find_next().find_next().attrs['title'].strip().split(' ')[0].strip()\n",
    "                er_date = review.find('span', {'class': 'rating-qualifier'}).get_text().strip()\n",
    "                statistics = review.find_all('span', {'class': 'count'})\n",
    "                er_useful = statistics[0].get_text().strip()\n",
    "                er_funny =  statistics[1].get_text().strip()\n",
    "                er_cool = statistics[2].get_text().strip()\n",
    "                reviewer = reviewer.append({'er_name': er_name,\n",
    "                                            'er_location': er_location,\n",
    "                                            'er_freinds': er_friends,\n",
    "                                            'er_reviews': er_reviews,\n",
    "                                            'er_photos': er_photos,\n",
    "                                            'er_rating': er_rating,\n",
    "                                            'er_date': er_date,\n",
    "                                            'er_text': er_text,\n",
    "                                            'er_useful': er_useful,\n",
    "                                            'er_funny': er_funny,\n",
    "                                            'er_cool': er_cool\n",
    "                                }, ignore_index = True)\n",
    "        except:\n",
    "            error_code = error_code + str(n_reviews) + '/'\n",
    "            continue\n",
    "        n_reviews += 20\n",
    "        time.sleep(np.random.uniform(5, 10))\n",
    "        try:\n",
    "            restaurant_link = 'https://www.yelp.com' + fetched_restaurants[similarity.argmax()].attrs['href'].split('?')[0] + '?start=' + str(n_reviews)\n",
    "            restaurant_content = BeautifulSoup(requests.get(restaurant_link).text)\n",
    "        except:\n",
    "            error_code = -3\n",
    "            return (None, None, None, None, error_code)\n",
    "    \n",
    "    \n",
    "    return (attributes, reviewer, fetched_restaurant, similarity_index, error_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_restaurants(data):\n",
    "   \n",
    "    \"\"\"\n",
    "    Fetch restaurants data from yelp and write them into three types of files:\n",
    "    <CAMIS>.csv contains reviews\n",
    "    attributes.csv contains restaurant attributes\n",
    "    info.csv contains technical info during scraping\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    TEMPLATE\n",
    "    (data = pd.DataFrame) -> None\n",
    "    \n",
    "    INPUT\n",
    "    data DataFrame that contains columns of CAMIS, DBA, BUILDING, STREET and BORO\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    from datetime import datetime\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    \n",
    "    directory = '../Yelp'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    attributes_ls = []\n",
    "    reviewer_ls = []\n",
    "    info = pd.DataFrame({'CAMIS':[],\n",
    "                         'DBA':[],\n",
    "                         'fetched_restaurant':[],\n",
    "                         'similarity_index':[],\n",
    "                         'error_code':[]\n",
    "                        })\n",
    "    for index, row in data.iterrows():\n",
    "        try:\n",
    "            restaurant_name = row['DBA']\n",
    "            location_name = row['BUILDING'] + ' ' + row['STREET'] + ' ' + row['BORO']\n",
    "            (attributes, reviewer, fetched_restaurant, similarity_index, error_code) = fetch_restaurant(restaurant_name, location_name)\n",
    "            if isinstance(error_code, int): # error code is int. no data is returned.\n",
    "                info = info.append({'CAMIS': row['CAMIS'],\n",
    "                                'DBA': row['DBA'],\n",
    "                                'fetched_restaurant': np.nan,\n",
    "                                'similarity_index': np.nan,\n",
    "                                'error_code': error_code\n",
    "                                    }, ignore_index = True)\n",
    "                continue\n",
    "            attributes.rename(row['CAMIS'], inplace = True)\n",
    "            attributes_ls.append(attributes)\n",
    "            temp_reviewer_path = '../Yelp/' + str(row['CAMIS']) + '.csv'\n",
    "            if os.path.isfile(temp_reviewer_path):\n",
    "                os.remove(temp_reviewer_path)\n",
    "            reviewer.to_csv(temp_reviewer_path) # save review information of each restaurant to separate files, indicated by CAMIS \n",
    "            info = info.append({'CAMIS': row['CAMIS'],\n",
    "                                'DBA': row['DBA'],\n",
    "                                'fetched_restaurant': fetched_restaurant,\n",
    "                                'similarity_index': similarity_index,\n",
    "                                'error_code': error_code,\n",
    "                                'record_time': datetime.now()\n",
    "                               }, ignore_index = True)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    header_attr = not os.path.isfile('../Yelp/attributes.csv') \n",
    "    header_info = not os.path.isfile('../Yelp/info.csv') \n",
    "    pd.DataFrame(attributes_ls).to_csv('../Yelp/attributes.csv', mode = 'a', header = header_attr) # save restaurant attributes\n",
    "    info.to_csv('../Yelp/info.csv', mode = 'a', header = header_info) # save scraping info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../Data/NYC_Rest_Inspect.csv')\n",
    "raw_data['INSPECTION DATE'] = pd.to_datetime(raw_data['INSPECTION DATE'], format = '%m/%d/%Y')\n",
    "raw_data['GRADE DATE'] = pd.to_datetime(raw_data['GRADE DATE'], format = '%m/%d/%Y')\n",
    "raw_data['RECORD DATE'] = pd.to_datetime(raw_data['RECORD DATE'], format = '%m/%d/%Y')\n",
    "data = raw_data[ (raw_data[\"BORO\"] == \"MANHATTAN\") & (raw_data[\"CUISINE DESCRIPTION\"] == \"American\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43184, 18)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "index = np.random.randint(0, data.shape[0] + 1, size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAMIS</th>\n",
       "      <th>DBA</th>\n",
       "      <th>BORO</th>\n",
       "      <th>BUILDING</th>\n",
       "      <th>STREET</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>PHONE</th>\n",
       "      <th>CUISINE DESCRIPTION</th>\n",
       "      <th>INSPECTION DATE</th>\n",
       "      <th>ACTION</th>\n",
       "      <th>VIOLATION CODE</th>\n",
       "      <th>VIOLATION DESCRIPTION</th>\n",
       "      <th>CRITICAL FLAG</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>GRADE DATE</th>\n",
       "      <th>RECORD DATE</th>\n",
       "      <th>INSPECTION TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24050</th>\n",
       "      <td>50005183</td>\n",
       "      <td>COCO &amp; CRU/SWEETWATER SOCIAL</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>643</td>\n",
       "      <td>BROADWAY</td>\n",
       "      <td>10012.0</td>\n",
       "      <td>2122530477</td>\n",
       "      <td>American</td>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>04L</td>\n",
       "      <td>Evidence of mice or live mice present in facil...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>Cycle Inspection / Initial Inspection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377867</th>\n",
       "      <td>41073985</td>\n",
       "      <td>HEARTLAND BREWERY</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>350</td>\n",
       "      <td>5 AVENUE</td>\n",
       "      <td>10118.0</td>\n",
       "      <td>2125633433</td>\n",
       "      <td>American</td>\n",
       "      <td>2018-04-13</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>06C</td>\n",
       "      <td>Food not protected from potential source of co...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>13.0</td>\n",
       "      <td>A</td>\n",
       "      <td>2018-04-13</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>Cycle Inspection / Initial Inspection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187794</th>\n",
       "      <td>40526406</td>\n",
       "      <td>CLUB MACANUDO (CIGAR BAR)</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>26</td>\n",
       "      <td>EAST   63 STREET</td>\n",
       "      <td>10065.0</td>\n",
       "      <td>2127528200</td>\n",
       "      <td>American</td>\n",
       "      <td>2017-07-20</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>04L</td>\n",
       "      <td>Evidence of mice or live mice present in facil...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>Cycle Inspection / Initial Inspection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269480</th>\n",
       "      <td>40671007</td>\n",
       "      <td>PIG &amp; WHISTLE ON 3RD</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>922</td>\n",
       "      <td>3 AVENUE</td>\n",
       "      <td>10022.0</td>\n",
       "      <td>2126884646</td>\n",
       "      <td>American</td>\n",
       "      <td>2017-09-08</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>10B</td>\n",
       "      <td>Plumbing not properly installed or maintained;...</td>\n",
       "      <td>Not Critical</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A</td>\n",
       "      <td>2017-09-08</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>Cycle Inspection / Re-inspection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284415</th>\n",
       "      <td>41479731</td>\n",
       "      <td>STILLWATER BAR &amp; GRILL</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>7880</td>\n",
       "      <td>EAST    4 STREET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2122532237</td>\n",
       "      <td>American</td>\n",
       "      <td>2017-10-17</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>06D</td>\n",
       "      <td>Food contact surface not properly washed, rins...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>12.0</td>\n",
       "      <td>A</td>\n",
       "      <td>2017-10-17</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>Cycle Inspection / Re-inspection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372034</th>\n",
       "      <td>41068920</td>\n",
       "      <td>THE SKINNY</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>174</td>\n",
       "      <td>ORCHARD STREET</td>\n",
       "      <td>10002.0</td>\n",
       "      <td>2122283668</td>\n",
       "      <td>American</td>\n",
       "      <td>2018-02-22</td>\n",
       "      <td>Establishment Closed by DOHMH.  Violations wer...</td>\n",
       "      <td>04L</td>\n",
       "      <td>Evidence of mice or live mice present in facil...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>Cycle Inspection / Re-inspection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183453</th>\n",
       "      <td>50012158</td>\n",
       "      <td>MEZZROW</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>163</td>\n",
       "      <td>W 10TH ST</td>\n",
       "      <td>10014.0</td>\n",
       "      <td>6464764346</td>\n",
       "      <td>American</td>\n",
       "      <td>2016-02-10</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>10F</td>\n",
       "      <td>Non-food contact surface improperly constructe...</td>\n",
       "      <td>Not Critical</td>\n",
       "      <td>10.0</td>\n",
       "      <td>A</td>\n",
       "      <td>2016-02-10</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>Cycle Inspection / Initial Inspection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132646</th>\n",
       "      <td>41520610</td>\n",
       "      <td>BAREBURGER</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>535</td>\n",
       "      <td>LAGUARDIA PLACE</td>\n",
       "      <td>10012.0</td>\n",
       "      <td>2124778125</td>\n",
       "      <td>American</td>\n",
       "      <td>2017-06-02</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>06D</td>\n",
       "      <td>Food contact surface not properly washed, rins...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>Cycle Inspection / Initial Inspection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137029</th>\n",
       "      <td>40567533</td>\n",
       "      <td>THE THIRSTY SCHOLAR</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>155</td>\n",
       "      <td>2 AVENUE</td>\n",
       "      <td>10003.0</td>\n",
       "      <td>2127776514</td>\n",
       "      <td>American</td>\n",
       "      <td>2016-08-04</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>06F</td>\n",
       "      <td>Wiping cloths soiled or not stored in sanitizi...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>12.0</td>\n",
       "      <td>A</td>\n",
       "      <td>2016-08-04</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>Cycle Inspection / Initial Inspection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349498</th>\n",
       "      <td>41467165</td>\n",
       "      <td>CHELSEA PAPAYA</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>171</td>\n",
       "      <td>WEST   23 STREET</td>\n",
       "      <td>10011.0</td>\n",
       "      <td>2123529060</td>\n",
       "      <td>American</td>\n",
       "      <td>2015-11-27</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>04M</td>\n",
       "      <td>Live roaches present in facility's food and/or...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>Cycle Inspection / Initial Inspection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CAMIS                           DBA       BORO BUILDING  \\\n",
       "24050   50005183  COCO & CRU/SWEETWATER SOCIAL  MANHATTAN      643   \n",
       "377867  41073985             HEARTLAND BREWERY  MANHATTAN      350   \n",
       "187794  40526406     CLUB MACANUDO (CIGAR BAR)  MANHATTAN       26   \n",
       "269480  40671007          PIG & WHISTLE ON 3RD  MANHATTAN      922   \n",
       "284415  41479731        STILLWATER BAR & GRILL  MANHATTAN     7880   \n",
       "372034  41068920                    THE SKINNY  MANHATTAN      174   \n",
       "183453  50012158                       MEZZROW  MANHATTAN      163   \n",
       "132646  41520610                    BAREBURGER  MANHATTAN      535   \n",
       "137029  40567533           THE THIRSTY SCHOLAR  MANHATTAN      155   \n",
       "349498  41467165                CHELSEA PAPAYA  MANHATTAN      171   \n",
       "\n",
       "                  STREET  ZIPCODE       PHONE CUISINE DESCRIPTION  \\\n",
       "24050           BROADWAY  10012.0  2122530477            American   \n",
       "377867          5 AVENUE  10118.0  2125633433            American   \n",
       "187794  EAST   63 STREET  10065.0  2127528200            American   \n",
       "269480          3 AVENUE  10022.0  2126884646            American   \n",
       "284415  EAST    4 STREET      NaN  2122532237            American   \n",
       "372034    ORCHARD STREET  10002.0  2122283668            American   \n",
       "183453         W 10TH ST  10014.0  6464764346            American   \n",
       "132646   LAGUARDIA PLACE  10012.0  2124778125            American   \n",
       "137029          2 AVENUE  10003.0  2127776514            American   \n",
       "349498  WEST   23 STREET  10011.0  2123529060            American   \n",
       "\n",
       "       INSPECTION DATE                                             ACTION  \\\n",
       "24050       2015-11-23    Violations were cited in the following area(s).   \n",
       "377867      2018-04-13    Violations were cited in the following area(s).   \n",
       "187794      2017-07-20    Violations were cited in the following area(s).   \n",
       "269480      2017-09-08    Violations were cited in the following area(s).   \n",
       "284415      2017-10-17    Violations were cited in the following area(s).   \n",
       "372034      2018-02-22  Establishment Closed by DOHMH.  Violations wer...   \n",
       "183453      2016-02-10    Violations were cited in the following area(s).   \n",
       "132646      2017-06-02    Violations were cited in the following area(s).   \n",
       "137029      2016-08-04    Violations were cited in the following area(s).   \n",
       "349498      2015-11-27    Violations were cited in the following area(s).   \n",
       "\n",
       "       VIOLATION CODE                              VIOLATION DESCRIPTION  \\\n",
       "24050             04L  Evidence of mice or live mice present in facil...   \n",
       "377867            06C  Food not protected from potential source of co...   \n",
       "187794            04L  Evidence of mice or live mice present in facil...   \n",
       "269480            10B  Plumbing not properly installed or maintained;...   \n",
       "284415            06D  Food contact surface not properly washed, rins...   \n",
       "372034            04L  Evidence of mice or live mice present in facil...   \n",
       "183453            10F  Non-food contact surface improperly constructe...   \n",
       "132646            06D  Food contact surface not properly washed, rins...   \n",
       "137029            06F  Wiping cloths soiled or not stored in sanitizi...   \n",
       "349498            04M  Live roaches present in facility's food and/or...   \n",
       "\n",
       "       CRITICAL FLAG  SCORE GRADE GRADE DATE RECORD DATE  \\\n",
       "24050       Critical   35.0   NaN        NaT  2018-11-12   \n",
       "377867      Critical   13.0     A 2018-04-13  2018-11-12   \n",
       "187794      Critical   31.0   NaN        NaT  2018-11-12   \n",
       "269480  Not Critical    4.0     A 2017-09-08  2018-11-12   \n",
       "284415      Critical   12.0     A 2017-10-17  2018-11-12   \n",
       "372034      Critical   33.0   NaN        NaT  2018-11-12   \n",
       "183453  Not Critical   10.0     A 2016-02-10  2018-11-12   \n",
       "132646      Critical   14.0   NaN        NaT  2018-11-12   \n",
       "137029      Critical   12.0     A 2016-08-04  2018-11-12   \n",
       "349498      Critical   19.0   NaN        NaT  2018-11-12   \n",
       "\n",
       "                              INSPECTION TYPE  \n",
       "24050   Cycle Inspection / Initial Inspection  \n",
       "377867  Cycle Inspection / Initial Inspection  \n",
       "187794  Cycle Inspection / Initial Inspection  \n",
       "269480       Cycle Inspection / Re-inspection  \n",
       "284415       Cycle Inspection / Re-inspection  \n",
       "372034       Cycle Inspection / Re-inspection  \n",
       "183453  Cycle Inspection / Initial Inspection  \n",
       "132646  Cycle Inspection / Initial Inspection  \n",
       "137029  Cycle Inspection / Initial Inspection  \n",
       "349498  Cycle Inspection / Initial Inspection  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[index[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_restaurants(batch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
