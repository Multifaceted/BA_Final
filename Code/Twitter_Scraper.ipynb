{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'chris evans'\n",
    "date = ('2011-06-22', '2011-08-22')\n",
    "page_scroll = 5\n",
    "username = 'qitianma'\n",
    "password = 'qitian1129'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_scrape(keyword, date, page_scroll, username, password):\n",
    "    \"\"\"\n",
    "    Please CHANGE your ChromeDriver executable_path!!!\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    (keyword = int, date = tuple, pageroll = int, username = str, password = str) -> data = pd.DataFrame\n",
    "    \n",
    "    keyword: the word you want to search\n",
    "    date: date[0] is the starting date, date[1] is the end date\n",
    "    page_scroll: the number of pages you want to scroll (the function must see the whole content before scraping)\n",
    "    username: your twitter username\n",
    "    password: your twitter password\n",
    "    \n",
    "    data: fetched data\n",
    "    \"\"\"\n",
    "\n",
    "    SCROLL_PAUSE_TIME = 2\n",
    "\n",
    "    from selenium import webdriver\n",
    "    from bs4 import BeautifulSoup\n",
    "    import time\n",
    "    import pandas as pd\n",
    "\n",
    "    # Open Browser (Please CHANGE your ChromeDriver executable_path!!!)\n",
    "    driver = webdriver.Chrome(executable_path = '/usr/bin/chromedriver')\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36\"}\n",
    "\n",
    "    # Log in Twitter Account\n",
    "    url = 'https://twitter.com/login'\n",
    "    driver.get(url)\n",
    "    username_box = driver.find_element_by_css_selector('#page-container > div > div.signin-wrapper > form > fieldset > div:nth-child(2) > input')\n",
    "    password_box = driver.find_element_by_css_selector('#page-container > div > div.signin-wrapper > form > fieldset > div:nth-child(3) > input')\n",
    "    username_box.send_keys(username)\n",
    "    password_box.send_keys(password)\n",
    "    driver.find_element_by_css_selector('#page-container > div > div.signin-wrapper > form > div.clearfix > button').click()\n",
    "\n",
    "    # Search Keyword\n",
    "    search_entry = keyword + ' since:' + date[0] + ' until:' + date[1]\n",
    "    search_box = driver.find_element_by_css_selector('#search-query')\n",
    "    search_box.send_keys(search_entry)\n",
    "    driver.find_element_by_css_selector('#global-nav-search > span > button').click()\n",
    "\n",
    "    # Scroll Pages\n",
    "    for page in range(page_scroll):\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Fetch Webpage & Parse Content\n",
    "    data = pd.DataFrame({'content': [], \n",
    "                         'usr': [], \n",
    "                         'account_id': [], \n",
    "                         'timestamp': [], \n",
    "                         'comment': [], \n",
    "                         'retweet': [], \n",
    "                         'favorite': [], \n",
    "                         'link': []})\n",
    "    souped_content = BeautifulSoup(driver.page_source)\n",
    "    driver.quit()\n",
    "    \n",
    "    # Extract Data\n",
    "    streams = souped_content.find_all('div', {'class': 'content'})\n",
    "    for stream in streams:\n",
    "        try:\n",
    "            header = stream.find('div', {'class': 'stream-item-header'})\n",
    "            if header is None:\n",
    "                continue\n",
    "            usr = header.find('span', {'class': \"FullNameGroup\"}).text.strip()\n",
    "            account_id = header.find('a', {'class': \"account-group js-account-group js-action-profile js-user-profile-link js-nav\"}).attrs['data-user-id']\n",
    "            timestamp = pd.to_datetime(header.find('span', {'class': \"_timestamp js-short-timestamp \"}).attrs['data-time-ms'], unit='ms')\n",
    "            link = header.find('a', {'class': \"tweet-timestamp js-permalink js-nav js-tooltip\"}).attrs['href']\n",
    "\n",
    "            text_container = stream.find('div', {'class': 'js-tweet-text-container'})\n",
    "            if text_container.find('p', {'class', 'TweetTextSize js-tweet-text tweet-text'}).attrs['lang'] != 'en':\n",
    "                continue\n",
    "            content = text_container.text.strip()\n",
    "\n",
    "            footer = stream.find('div', {'class': 'stream-item-footer'})\n",
    "            statistics = footer.find_all('span', {'class': 'ProfileTweet-actionCount'})\n",
    "            try: \n",
    "                comment =  statistics[0].attrs['data-tweet-stat-count']\n",
    "            except:\n",
    "                comment = 0\n",
    "            try:\n",
    "                retweet =  statistics[1].attrs['data-tweet-stat-count']\n",
    "            except:\n",
    "                retweet = 0\n",
    "            try:\n",
    "                favorite =  statistics[2].attrs['data-tweet-stat-count']\n",
    "            except:\n",
    "                favorite = 0\n",
    "            data = data.append({'content': content, \n",
    "                                'usr': usr, \n",
    "                                'account_id': account_id, \n",
    "                                'timestamp': timestamp, \n",
    "                                'comment': comment, \n",
    "                                'retweet': retweet, \n",
    "                                'favorite': favorite, \n",
    "                                'link': link},\n",
    "                                ignore_index=True)\n",
    "        except:\n",
    "            continue\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtwitter_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_scroll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Please CHANGE your ChromeDriver executable_path!!!\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "(keyword = int, date = tuple, pageroll = int, username = str, password = str) -> data = pd.DataFrame\n",
       "\n",
       "keyword: the word you want to search\n",
       "date: date[0] is the starting date, date[1] is the end date\n",
       "page_scroll: the number of pages you want to scroll (the function must see the whole content before scraping)\n",
       "username: your twitter username\n",
       "password: your twitter password\n",
       "\n",
       "data: fetched data\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/NLP/Code/<ipython-input-5-0f4c05726a6a>\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "twitter_scrape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_scrape_byday(keyword, date, page_scroll, username, password):\n",
    "    from selenium import webdriver\n",
    "    from bs4 import BeautifulSoup\n",
    "    import time\n",
    "    import pandas as pd\n",
    "    \n",
    "    date_range = pd.date_range(date[0], date[1], freq = 'D')\n",
    "    date_range = [str(date).split()[0] for date in date_range]\n",
    "    data = pd.DataFrame({'content': [], \n",
    "                         'usr': [], \n",
    "                         'account_id': [], \n",
    "                         'timestamp': [], \n",
    "                         'comment': [], \n",
    "                         'retweet': [], \n",
    "                         'favorite': [], \n",
    "                         'link': []})\n",
    "    \n",
    "    SCROLL_PAUSE_TIME = 2\n",
    "\n",
    "    # Open Browser (Please CHANGE your ChromeDriver executable_path!!!)\n",
    "    driver = webdriver.Chrome(executable_path = '/usr/bin/chromedriver')\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36\"}\n",
    "\n",
    "    # Log in Twitter Account\n",
    "    url = 'https://twitter.com/login'\n",
    "    driver.get(url)\n",
    "    username_box = driver.find_element_by_css_selector('#page-container > div > div.signin-wrapper > form > fieldset > div:nth-child(2) > input')\n",
    "    password_box = driver.find_element_by_css_selector('#page-container > div > div.signin-wrapper > form > fieldset > div:nth-child(3) > input')\n",
    "    username_box.send_keys(username)\n",
    "    password_box.send_keys(password)\n",
    "    driver.find_element_by_css_selector('#page-container > div > div.signin-wrapper > form > div.clearfix > button').click()\n",
    "    \n",
    "    for date_idx in range(len(date_range) - 1):\n",
    "        date_tup = (date_range[date_idx], date_range[date_idx+1]) \n",
    "        search_entry = keyword + ' since:' + date_tup[0] + ' until:' + date_tup[1]\n",
    "        search_box = driver.find_element_by_css_selector('#search-query')\n",
    "        search_box.clear()\n",
    "        search_box.send_keys(search_entry)\n",
    "        driver.find_element_by_css_selector('#global-nav-search > span > button').click()\n",
    "\n",
    "        # Scroll Pages\n",
    "        for page in range(page_scroll):\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Fetch Webpage & Parse Content\n",
    "        souped_content = BeautifulSoup(driver.page_source)\n",
    "\n",
    "        # Extract Data\n",
    "        streams = souped_content.find_all('div', {'class': 'content'})\n",
    "        for stream in streams:\n",
    "            try:\n",
    "                header = stream.find('div', {'class': 'stream-item-header'})\n",
    "                if header is None:\n",
    "                    continue\n",
    "                usr = header.find('span', {'class': \"FullNameGroup\"}).text.strip()\n",
    "                account_id = header.find('a', {'class': \"account-group js-account-group js-action-profile js-user-profile-link js-nav\"}).attrs['data-user-id']\n",
    "                timestamp = pd.to_datetime(header.find('span', {'class': \"_timestamp js-short-timestamp \"}).attrs['data-time-ms'], unit='ms')\n",
    "                link = header.find('a', {'class': \"tweet-timestamp js-permalink js-nav js-tooltip\"}).attrs['href']\n",
    "\n",
    "                text_container = stream.find('div', {'class': 'js-tweet-text-container'})\n",
    "                if text_container.find('p', {'class', 'TweetTextSize js-tweet-text tweet-text'}).attrs['lang'] != 'en':\n",
    "                    continue\n",
    "                content = text_container.text.strip()\n",
    "\n",
    "                footer = stream.find('div', {'class': 'stream-item-footer'})\n",
    "                statistics = footer.find_all('span', {'class': 'ProfileTweet-actionCount'})\n",
    "                try: \n",
    "                    comment =  statistics[0].attrs['data-tweet-stat-count']\n",
    "                except:\n",
    "                    comment = 0\n",
    "                try:\n",
    "                    retweet =  statistics[1].attrs['data-tweet-stat-count']\n",
    "                except:\n",
    "                    retweet = 0\n",
    "                try:\n",
    "                    favorite =  statistics[2].attrs['data-tweet-stat-count']\n",
    "                except:\n",
    "                    favorite = 0\n",
    "                data = data.append({'content': content, \n",
    "                                    'usr': usr, \n",
    "                                    'account_id': account_id, \n",
    "                                    'timestamp': timestamp, \n",
    "                                    'comment': comment, \n",
    "                                    'retweet': retweet, \n",
    "                                    'favorite': favorite, \n",
    "                                    'link': link},\n",
    "                                    ignore_index=True)\n",
    "            except:\n",
    "                continue\n",
    "    driver.quit()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = twitter_scrape_byday(keyword, date, page_scroll, username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['polarity'] = data2['content'].apply(lambda x: sid.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['date'] = data2['timestamp'].apply(lambda x: str(x).split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "po = data2.groupby('date').apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-06-22</th>\n",
       "      <td>0.004979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-23</th>\n",
       "      <td>0.031122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-24</th>\n",
       "      <td>0.187331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-25</th>\n",
       "      <td>0.162548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-26</th>\n",
       "      <td>0.136949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-27</th>\n",
       "      <td>0.176067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-28</th>\n",
       "      <td>0.110033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-29</th>\n",
       "      <td>0.141255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-30</th>\n",
       "      <td>0.143219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-01</th>\n",
       "      <td>0.241809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-02</th>\n",
       "      <td>0.131407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-03</th>\n",
       "      <td>0.182311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-04</th>\n",
       "      <td>0.135170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-05</th>\n",
       "      <td>0.273852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-06</th>\n",
       "      <td>0.115517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-07</th>\n",
       "      <td>0.251045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-08</th>\n",
       "      <td>0.248250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-09</th>\n",
       "      <td>0.202393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-10</th>\n",
       "      <td>0.164687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-11</th>\n",
       "      <td>0.146550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-12</th>\n",
       "      <td>0.149272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-13</th>\n",
       "      <td>0.218145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-14</th>\n",
       "      <td>0.202506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-15</th>\n",
       "      <td>0.190109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-16</th>\n",
       "      <td>0.210981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-17</th>\n",
       "      <td>0.100524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-18</th>\n",
       "      <td>0.128498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-19</th>\n",
       "      <td>0.197498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-20</th>\n",
       "      <td>0.157603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-21</th>\n",
       "      <td>0.232543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-24</th>\n",
       "      <td>0.359716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-25</th>\n",
       "      <td>0.238385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-26</th>\n",
       "      <td>0.251710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-27</th>\n",
       "      <td>0.177141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-28</th>\n",
       "      <td>0.163917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-29</th>\n",
       "      <td>0.148288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-30</th>\n",
       "      <td>0.200249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-31</th>\n",
       "      <td>0.224588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-01</th>\n",
       "      <td>0.291422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-02</th>\n",
       "      <td>0.201034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-03</th>\n",
       "      <td>0.154062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-04</th>\n",
       "      <td>0.142656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-05</th>\n",
       "      <td>0.244343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-06</th>\n",
       "      <td>0.192250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-07</th>\n",
       "      <td>0.223238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-08</th>\n",
       "      <td>0.177905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-09</th>\n",
       "      <td>0.176869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-10</th>\n",
       "      <td>0.205474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-11</th>\n",
       "      <td>0.100018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-12</th>\n",
       "      <td>0.222527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-13</th>\n",
       "      <td>0.222542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-14</th>\n",
       "      <td>0.272515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-15</th>\n",
       "      <td>0.109304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-16</th>\n",
       "      <td>0.114237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-17</th>\n",
       "      <td>0.045571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-18</th>\n",
       "      <td>0.103738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-19</th>\n",
       "      <td>0.091496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-20</th>\n",
       "      <td>0.089138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-21</th>\n",
       "      <td>0.138952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-16</th>\n",
       "      <td>0.700300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            polarity\n",
       "date                \n",
       "2011-06-22  0.004979\n",
       "2011-06-23  0.031122\n",
       "2011-06-24  0.187331\n",
       "2011-06-25  0.162548\n",
       "2011-06-26  0.136949\n",
       "2011-06-27  0.176067\n",
       "2011-06-28  0.110033\n",
       "2011-06-29  0.141255\n",
       "2011-06-30  0.143219\n",
       "2011-07-01  0.241809\n",
       "2011-07-02  0.131407\n",
       "2011-07-03  0.182311\n",
       "2011-07-04  0.135170\n",
       "2011-07-05  0.273852\n",
       "2011-07-06  0.115517\n",
       "2011-07-07  0.251045\n",
       "2011-07-08  0.248250\n",
       "2011-07-09  0.202393\n",
       "2011-07-10  0.164687\n",
       "2011-07-11  0.146550\n",
       "2011-07-12  0.149272\n",
       "2011-07-13  0.218145\n",
       "2011-07-14  0.202506\n",
       "2011-07-15  0.190109\n",
       "2011-07-16  0.210981\n",
       "2011-07-17  0.100524\n",
       "2011-07-18  0.128498\n",
       "2011-07-19  0.197498\n",
       "2011-07-20  0.157603\n",
       "2011-07-21  0.232543\n",
       "...              ...\n",
       "2011-07-24  0.359716\n",
       "2011-07-25  0.238385\n",
       "2011-07-26  0.251710\n",
       "2011-07-27  0.177141\n",
       "2011-07-28  0.163917\n",
       "2011-07-29  0.148288\n",
       "2011-07-30  0.200249\n",
       "2011-07-31  0.224588\n",
       "2011-08-01  0.291422\n",
       "2011-08-02  0.201034\n",
       "2011-08-03  0.154062\n",
       "2011-08-04  0.142656\n",
       "2011-08-05  0.244343\n",
       "2011-08-06  0.192250\n",
       "2011-08-07  0.223238\n",
       "2011-08-08  0.177905\n",
       "2011-08-09  0.176869\n",
       "2011-08-10  0.205474\n",
       "2011-08-11  0.100018\n",
       "2011-08-12  0.222527\n",
       "2011-08-13  0.222542\n",
       "2011-08-14  0.272515\n",
       "2011-08-15  0.109304\n",
       "2011-08-16  0.114237\n",
       "2011-08-17  0.045571\n",
       "2011-08-18  0.103738\n",
       "2011-08-19  0.091496\n",
       "2011-08-20  0.089138\n",
       "2011-08-21  0.138952\n",
       "2018-08-16  0.700300\n",
       "\n",
       "[62 rows x 1 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7686339668>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(pd.to_datetime(po['polarity'].index[:-1]), po['polarity'].values[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2011-06-22', '2011-06-23', '2011-06-24', '2011-06-25',\n",
       "               '2011-06-26', '2011-06-27', '2011-06-28', '2011-06-29',\n",
       "               '2011-06-30', '2011-07-01', '2011-07-02', '2011-07-03',\n",
       "               '2011-07-04', '2011-07-05', '2011-07-06', '2011-07-07',\n",
       "               '2011-07-08', '2011-07-09', '2011-07-10', '2011-07-11',\n",
       "               '2011-07-12', '2011-07-13', '2011-07-14', '2011-07-15',\n",
       "               '2011-07-16', '2011-07-17', '2011-07-18', '2011-07-19',\n",
       "               '2011-07-20', '2011-07-21', '2011-07-22', '2011-07-23',\n",
       "               '2011-07-24', '2011-07-25', '2011-07-26', '2011-07-27',\n",
       "               '2011-07-28', '2011-07-29', '2011-07-30', '2011-07-31',\n",
       "               '2011-08-01', '2011-08-02', '2011-08-03', '2011-08-04',\n",
       "               '2011-08-05', '2011-08-06', '2011-08-07', '2011-08-08',\n",
       "               '2011-08-09', '2011-08-10', '2011-08-11', '2011-08-12',\n",
       "               '2011-08-13', '2011-08-14', '2011-08-15', '2011-08-16',\n",
       "               '2011-08-17', '2011-08-18', '2011-08-19', '2011-08-20',\n",
       "               '2011-08-21'],\n",
       "              dtype='datetime64[ns]', name='date', freq=None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(po['polarity'].index)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myearfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Convert argument to datetime.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "arg : integer, float, string, datetime, list, tuple, 1-d array, Series\n",
       "\n",
       "    .. versionadded:: 0.18.1\n",
       "\n",
       "       or DataFrame/dict-like\n",
       "\n",
       "errors : {'ignore', 'raise', 'coerce'}, default 'raise'\n",
       "\n",
       "    - If 'raise', then invalid parsing will raise an exception\n",
       "    - If 'coerce', then invalid parsing will be set as NaT\n",
       "    - If 'ignore', then invalid parsing will return the input\n",
       "dayfirst : boolean, default False\n",
       "    Specify a date parse order if `arg` is str or its list-likes.\n",
       "    If True, parses dates with the day first, eg 10/11/12 is parsed as\n",
       "    2012-11-10.\n",
       "    Warning: dayfirst=True is not strict, but will prefer to parse\n",
       "    with day first (this is a known bug, based on dateutil behavior).\n",
       "yearfirst : boolean, default False\n",
       "    Specify a date parse order if `arg` is str or its list-likes.\n",
       "\n",
       "    - If True parses dates with the year first, eg 10/11/12 is parsed as\n",
       "      2010-11-12.\n",
       "    - If both dayfirst and yearfirst are True, yearfirst is preceded (same\n",
       "      as dateutil).\n",
       "\n",
       "    Warning: yearfirst=True is not strict, but will prefer to parse\n",
       "    with year first (this is a known bug, based on dateutil beahavior).\n",
       "\n",
       "    .. versionadded:: 0.16.1\n",
       "\n",
       "utc : boolean, default None\n",
       "    Return UTC DatetimeIndex if True (converting any tz-aware\n",
       "    datetime.datetime objects as well).\n",
       "box : boolean, default True\n",
       "\n",
       "    - If True returns a DatetimeIndex\n",
       "    - If False returns ndarray of values.\n",
       "format : string, default None\n",
       "    strftime to parse time, eg \"%d/%m/%Y\", note that \"%f\" will parse\n",
       "    all the way up to nanoseconds.\n",
       "exact : boolean, True by default\n",
       "\n",
       "    - If True, require an exact format match.\n",
       "    - If False, allow the format to match anywhere in the target string.\n",
       "\n",
       "unit : string, default 'ns'\n",
       "    unit of the arg (D,s,ms,us,ns) denote the unit, which is an\n",
       "    integer or float number. This will be based off the origin.\n",
       "    Example, with unit='ms' and origin='unix' (the default), this\n",
       "    would calculate the number of milliseconds to the unix epoch start.\n",
       "infer_datetime_format : boolean, default False\n",
       "    If True and no `format` is given, attempt to infer the format of the\n",
       "    datetime strings, and if it can be inferred, switch to a faster\n",
       "    method of parsing them. In some cases this can increase the parsing\n",
       "    speed by ~5-10x.\n",
       "origin : scalar, default is 'unix'\n",
       "    Define the reference date. The numeric values would be parsed as number\n",
       "    of units (defined by `unit`) since this reference date.\n",
       "\n",
       "    - If 'unix' (or POSIX) time; origin is set to 1970-01-01.\n",
       "    - If 'julian', unit must be 'D', and origin is set to beginning of\n",
       "      Julian Calendar. Julian day number 0 is assigned to the day starting\n",
       "      at noon on January 1, 4713 BC.\n",
       "    - If Timestamp convertible, origin is set to Timestamp identified by\n",
       "      origin.\n",
       "\n",
       "    .. versionadded:: 0.20.0\n",
       "cache : boolean, default False\n",
       "    If True, use a cache of unique, converted dates to apply the datetime\n",
       "    conversion. May produce sigificant speed-up when parsing duplicate date\n",
       "    strings, especially ones with timezone offsets.\n",
       "\n",
       "    .. versionadded:: 0.23.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "ret : datetime if parsing succeeded.\n",
       "    Return type depends on input:\n",
       "\n",
       "    - list-like: DatetimeIndex\n",
       "    - Series: Series of datetime64 dtype\n",
       "    - scalar: Timestamp\n",
       "\n",
       "    In case when it is not possible to return designated types (e.g. when\n",
       "    any element of input is before Timestamp.min or after Timestamp.max)\n",
       "    return will have datetime.datetime type (or corresponding\n",
       "    array/Series).\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Assembling a datetime from multiple columns of a DataFrame. The keys can be\n",
       "common abbreviations like ['year', 'month', 'day', 'minute', 'second',\n",
       "'ms', 'us', 'ns']) or plurals of the same\n",
       "\n",
       ">>> df = pd.DataFrame({'year': [2015, 2016],\n",
       "                       'month': [2, 3],\n",
       "                       'day': [4, 5]})\n",
       ">>> pd.to_datetime(df)\n",
       "0   2015-02-04\n",
       "1   2016-03-05\n",
       "dtype: datetime64[ns]\n",
       "\n",
       "If a date does not meet the `timestamp limitations\n",
       "<http://pandas.pydata.org/pandas-docs/stable/timeseries.html\n",
       "#timeseries-timestamp-limits>`_, passing errors='ignore'\n",
       "will return the original input instead of raising any exception.\n",
       "\n",
       "Passing errors='coerce' will force an out-of-bounds date to NaT,\n",
       "in addition to forcing non-dates (or non-parseable dates) to NaT.\n",
       "\n",
       ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='ignore')\n",
       "datetime.datetime(1300, 1, 1, 0, 0)\n",
       ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')\n",
       "NaT\n",
       "\n",
       "Passing infer_datetime_format=True can often-times speedup a parsing\n",
       "if its not an ISO8601 format exactly, but in a regular format.\n",
       "\n",
       ">>> s = pd.Series(['3/11/2000', '3/12/2000', '3/13/2000']*1000)\n",
       "\n",
       ">>> s.head()\n",
       "0    3/11/2000\n",
       "1    3/12/2000\n",
       "2    3/13/2000\n",
       "3    3/11/2000\n",
       "4    3/12/2000\n",
       "dtype: object\n",
       "\n",
       ">>> %timeit pd.to_datetime(s,infer_datetime_format=True)\n",
       "100 loops, best of 3: 10.4 ms per loop\n",
       "\n",
       ">>> %timeit pd.to_datetime(s,infer_datetime_format=False)\n",
       "1 loop, best of 3: 471 ms per loop\n",
       "\n",
       "Using a unix epoch time\n",
       "\n",
       ">>> pd.to_datetime(1490195805, unit='s')\n",
       "Timestamp('2017-03-22 15:16:45')\n",
       ">>> pd.to_datetime(1490195805433502912, unit='ns')\n",
       "Timestamp('2017-03-22 15:16:45.433502912')\n",
       "\n",
       ".. warning:: For float arg, precision rounding might happen. To prevent\n",
       "    unexpected behavior use a fixed-width exact type.\n",
       "\n",
       "Using a non-unix epoch origin\n",
       "\n",
       ">>> pd.to_datetime([1, 2, 3], unit='D',\n",
       "                   origin=pd.Timestamp('1960-01-01'))\n",
       "0    1960-01-02\n",
       "1    1960-01-03\n",
       "2    1960-01-04\n",
       "\n",
       "See also\n",
       "--------\n",
       "pandas.DataFrame.astype : Cast argument to a specified dtype.\n",
       "pandas.to_timedelta : Convert argument to timedelta.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.to_datetime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(data.loc[1, 'content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
